{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文大部分内容来自机器之心和qq_34139222的博客"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动机\n",
    "深度网络的超参数往往会比较多，如何选取合适的值，则成为一个很困扰的问题。比如，这里是卷积神经元中的一些经典的超参数，究竟应该选哪个，希望这篇文章能提供解决的方法：\n",
    "![hyperparam](https://raw.githubusercontent.com/HuangYiran/readPaper/master/fotos/hyperParameter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 几种可能的方法\n",
    "- 启动网格搜索grid search，尝试检查每种可能的参数组合，当有一种组合优化了你的标准时，就停止搜索。这种方法一般比较耗时。它有个致命缺点，在高纬度会发生维度灾难\n",
    "- 可以使用随机搜索，这种方法可以随机检查超参数的空间，但速度更快而且大多时候也更好\n",
    "- 贝叶斯优化--我们为超参数设置一个先决条件，然后在观察不同实验的同时逐步更新他，这让我们可以更合理的拟合超参数空间，从而更好的找到最小值。它的本质其实是一种回归模型，即利用回归模型预测的函数值来选择下一个搜索点。贝叶斯优化有两个主要的要素：目标函数（objective function）和代理模型（surrogate model）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "贝叶斯优化算法简化\n",
    "选取m个点x1,..xm作为prior，假设他们服从多变量高斯分布\n",
    "for t=1,2...n do\n",
    "  最大化AF求得下一个采样点x0\n",
    "  采样目标函数位于x0处的值y0\n",
    "  假设x0,x1....xm服从多变量高斯分布\n",
    "# 其中AF是收获函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperopt库为python中的模型选择和参数优化提供了算法和并行方案。机器学习常见的模型有KNN,SVM，PCA，决策树，GBDT等一系列的算法，但是在实际应用中，我们需要选取合适的模型，并对模型调参，得到一组合适的参数。尤其是在模型的调参阶段，需要花费大量的时间和精力，却又效率低下。但是我们可以换一个角度来看待这个问题，模型的选取，以及模型中需要调节的参数，可以看做是一组变量，模型的质量标准（比如正确率，AUC）等等可以看做是目标函数，这个问题就是超参数的优化的问题。我们可以使用搜索算法来解决。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q (args) :\n",
    "    x, y = args\n",
    "    return x ∗∗ 2 + y ∗∗ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperopt提供了一个优化接口，这个接口接受一个评估函数和参数空间，能计算出参数空间内的一个点的损失函数值。用户还要指定空间内参数的分布情况。<br> \n",
    "Hyheropt四个重要的因素：指定需要最小化的函数，搜索的空间，采样的数据集(trails database)（可选），搜索的算法（可选）。 <br>\n",
    "首先，定义一个目标函数,接受一个变量,计算后返回一个函数的损失值，比如要最小化函数q(x,y) = x**2 + y**2:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "space = [hp.uniform(’x’, 0, 1), hp.normal(’y’, 0, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，定义一个参数空间，比如x在0-1区间内取值，y是实数，所以<br>\n",
    "\n",
    "第三，指定搜索的算法，算法也就是hyperopt的fmin函数的algo参数的取值。当前支持的算法由随机搜索(对应是hyperopt.rand.suggest)，模拟退火(对应是hyperopt.anneal.suggest)，TPE算法。举个栗子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, rand, tpe, space_eval\n",
    "best = fmin(q, space, algo=rand.suggest)\n",
    "print space_eval(space, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搜索算法本身也有内置的参数决定如何去优化目标函数，我们可以指定搜索算法的参数，比如针对TPE，指定jobs："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from hyperopt import hp, fmin, tpe\n",
    "algo = partial(tpe.suggest, n_startup_jobs=10)\n",
    "best = fmin(q, space, algo=algo)\n",
    "print space_eval(space, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于参数空间的设置，比如优化函数q，输入fmin(q,space=hp.uniform(‘a’,0,1)).hp.uniform函数的第一个参数是标签，每个超参数在参数空间内必须具有独一无二的标签。hp.uniform指定了参数的分布。其他的参数分布比如 <br>\n",
    "hp.choice返回一个选项，选项可以是list或者tuple.options可以是嵌套的表达式，用于组成条件参数。 <br>\n",
    "hp.pchoice(label,p_options)以一定的概率返回一个p_options的一个选项。这个选项使得函数在搜索过程中对每个选项的可能性不均匀。 <br>\n",
    "hp.uniform(label,low,high)参数在low和high之间均匀分布。 <br>\n",
    "hp.quniform(label,low,high,q),参数的取值是round(uniform(low,high)/q)*q，适用于那些离散的取值。 <br>\n",
    "hp.loguniform(label,low,high)绘制exp(uniform(low,high)),变量的取值范围是[exp(low),exp(high)] <br>\n",
    "hp.randint(label,upper) 返回一个在[0,upper)前闭后开的区间内的随机整数。 <br>\n",
    "搜索空间可以含有list和dictionary.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "list_space = [\n",
    "hp.uniform(’a’, 0, 1),\n",
    "hp.loguniform(’b’, 0, 1)]\n",
    "tuple_space = (\n",
    "hp.uniform(’a’, 0, 1),\n",
    "hp.loguniform(’b’, 0, 1))\n",
    "dict_space = {\n",
    "’a’: hp.uniform(’a’, 0, 1),\n",
    "’b’: hp.loguniform(’b’, 0, 1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用sample函数从参数空间内采样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt.pyll.stochasti import sample\n",
    "print sample(list_space)\n",
    "# => [0.13, .235]\n",
    "print sample(nested_space)\n",
    "# => [[{’case’: 1, ’a’, 0.12‘}, {’case’: 2, ’b’: 2.3}],\n",
    "# ’extra_literal_string’,\n",
    "# 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在参数空间内使用函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt.pyll import scope\n",
    "def foo(x):\n",
    "return str(x) ∗ 3\n",
    "expr_space = {\n",
    "’a’: 1 + hp.uniform(’a’, 0, 1),\n",
    "’b’: scope.minimum(hp.loguniform(’b’, 0, 1), 10),\n",
    "’c’: scope.call(foo, args=(hp.randint(’c’, 5),)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2-tf",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
